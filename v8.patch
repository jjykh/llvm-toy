diff --git a/.gitattributes b/.gitattributes
index 7ef1e1b74b..11113c22ad 100644
--- a/.gitattributes
+++ b/.gitattributes
@@ -3,3 +3,4 @@
 # Do not modify line endings for binary files (which are sometimes auto
 # detected as text files by git).
 *.png binary
+*.so binary
diff --git a/BUILD.gn b/BUILD.gn
index 75bc940455..0201210679 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -162,8 +162,28 @@ declare_args() {
 
   # Enable minor mark compact.
   v8_enable_minor_mc = true
+
+  #if UC_BUILD_TF_LLVM_BACKEND
+  v8_enable_llvm = false
+
+  #endif
+}
+
+#if UC_BUILD_TF_LLVM_BACKEND
+if (uc_build_tf_llvm_backend && current_toolchain == v8_snapshot_toolchain) {
+  v8_enable_llvm = true
+}
+if (v8_enable_llvm) {
+  v8_enable_disassembler = true
+  v8_enable_object_print = true
+}
+
+if (uc_build_tf_llvm_backend) {
+  v8_enable_embedded_builtins = true
 }
 
+#endif
+
 # Derived defaults.
 if (v8_enable_verify_heap == "") {
   v8_enable_verify_heap = v8_enable_debugging_features
@@ -192,6 +212,10 @@ if (uc_build_embedded_bytecode_handlers) {
   v8_enable_embedded_builtins = true
 }
 
+if (uc_build_v8_interpreted_regexp) {
+  v8_interpreted_regexp = true
+}
+
 assert(!v8_enable_embedded_builtins || v8_use_snapshot,
        "Embedded builtins only work with snapshots")
 
@@ -632,6 +656,20 @@ config("toolchain") {
   }
 }
 
+#if UC_BUILD_TF_LLVM_BACKEND
+if (v8_enable_llvm) {
+  config("llvm_configs") {
+    include_dirs = [ "src/llvm/include" ]
+    libs = [ "LLVM-8" ]
+    defines = [ "LLVMLOG_LEVEL=1" ]
+    ldflags = [ "-Wl,-rpath,../../v8/lib" ]
+
+    lib_dirs = [ "lib/" ]
+  }
+}
+
+#endif
+
 # Configs for code coverage with gcov. Separate configs for cflags and ldflags
 # to selectively influde cflags in non-test targets only.
 config("v8_gcov_coverage_cflags") {
@@ -1501,6 +1539,56 @@ v8_source_set("v8_initializers") {
   }
 
   configs = [ ":internal_config" ]
+
+  #if UC_BUILD_TF_LLVM_BACKEND
+  if (v8_enable_llvm) {
+    llvm_sources = [
+      "src/llvm/abbreviated-types.h",
+      "src/llvm/abbreviations.h",
+      "src/llvm/basic-block-manager.cc",
+      "src/llvm/basic-block-manager.h",
+      "src/llvm/basic-block.cc",
+      "src/llvm/basic-block.h",
+      "src/llvm/common-values.cc",
+      "src/llvm/common-values.h",
+      "src/llvm/compile.cc",
+      "src/llvm/compile.h",
+      "src/llvm/compiler-state.cc",
+      "src/llvm/compiler-state.h",
+      "src/llvm/exception-table-arm.cc",
+      "src/llvm/exception-table-arm.h",
+      "src/llvm/initialize-llvm.cc",
+      "src/llvm/initialize-llvm.h",
+      "src/llvm/intrinsic-repository.cc",
+      "src/llvm/intrinsic-repository.h",
+      "src/llvm/liveness-analysis-visitor.cc",
+      "src/llvm/liveness-analysis-visitor.h",
+      "src/llvm/llvm-headers.h",
+      "src/llvm/llvm-tf-builder.cc",
+      "src/llvm/llvm-tf-builder.h",
+      "src/llvm/load-constant-recorder.cc",
+      "src/llvm/load-constant-recorder.h",
+      "src/llvm/log.cpp",
+      "src/llvm/log.h",
+      "src/llvm/output.cc",
+      "src/llvm/output.h",
+      "src/llvm/stack-map-info.cc",
+      "src/llvm/stack-map-info.h",
+      "src/llvm/stack-maps.cc",
+      "src/llvm/stack-maps.h",
+      "src/llvm/tf/schedule-emitter.cc",
+      "src/llvm/tf/schedule-emitter.h",
+      "src/llvm/tf/tf-visitor.h",
+      "src/llvm/tf/v8-codegen.cc",
+      "src/llvm/tf/v8-codegen.h",
+      "src/llvm/tf/v8-pass-manager.cc",
+      "src/llvm/tf/v8-pass-manager.h",
+    ]
+    sources += llvm_sources
+    configs += [ ":llvm_configs" ]
+  }
+
+  #endif
 }
 
 v8_source_set("v8_init") {
@@ -1521,6 +1609,13 @@ v8_source_set("v8_init") {
   }
 
   configs = [ ":internal_config" ]
+
+  #if UC_BUILD_TF_LLVM_BACKEND
+  if (v8_enable_llvm) {
+    configs += [ ":llvm_configs" ]
+  }
+
+  #endif
 }
 
 # This is split out to be a non-code containing target that the Chromium browser
@@ -3256,6 +3351,13 @@ if (v8_use_snapshot && current_toolchain == v8_snapshot_toolchain) {
 
     configs = [ ":internal_config" ]
 
+    #if UC_BUILD_TF_LLVM_BACKEND
+    if (v8_enable_llvm) {
+      configs += [ ":llvm_configs" ]
+    }
+
+    #endif
+
     deps = [
       ":v8_base",
       ":v8_init",
diff --git a/gni/v8.gni b/gni/v8.gni
index e6f9c2424d..acea2acfd1 100644
--- a/gni/v8.gni
+++ b/gni/v8.gni
@@ -112,7 +112,13 @@ if (is_debug && !v8_optimized_debug) {
   # TODO(crbug.com/621335) Rework this so that we don't have the confusion
   # between "optimize_speed" and "optimize_max".
   if (((is_posix && !is_android) || is_fuchsia) && !using_sanitizer) {
-    v8_add_configs += [ "//build/config/compiler:optimize_speed" ]
+#if UC_BUILD_TF_LLVM_BACKEND
+    if (uc_build_tf_llvm_backend) {
+      v8_add_configs += [ "//build/config/compiler:no_optimize" ]
+    } else {
+      v8_add_configs += [ "//build/config/compiler:optimize_speed" ]
+    }
+#endif
   } else {
     v8_add_configs += [ "//build/config/compiler:optimize_max" ]
   }
diff --git a/include/v8.h b/include/v8.h
index 853167e9e8..9ba65e8482 100644
--- a/include/v8.h
+++ b/include/v8.h
@@ -10864,6 +10864,21 @@ void DeleteStdString(std::string*);
 const char* GetCString(std::string* s);
 #endif
 
+#if defined(UC_BUILD_CRASH_CALLBACK)
+// for crash callback info: u4memory
+// Get last few messages when v8 meet oom crash.
+const char* GetLastFewMessagesOnOOM();
+// Get last few messages when v8 meet oom crash.
+const char* GetStackTraceOnOOM();
+
+// Get last few messages of isolate, buff len must bigger than
+// kTraceRingBufferSize which can be get by GetLastFewMessages(nullptr, nullptr)
+int GetLastFewMessages(Isolate* isolate, char* buff);
+// Get last few messages of isolate, buff len must bigger than
+// kStacktraceBufferSize which can be get by GetStackTrace(nullptr, nullptr)
+int GetStackTrace(Isolate* isolate, char* buff);
+#endif  // defined(UC_BUILD_CRASH_CALLBACK)
+
 }  // namespace v8
 
 
diff --git a/src/api-compat-m63.cc b/src/api-compat-m63.cc
index 2db3d5918d..03d77100dd 100644
--- a/src/api-compat-m63.cc
+++ b/src/api-compat-m63.cc
@@ -322,6 +322,20 @@ void _ZN2v88TryCatchC1EPNS_7IsolateE(void*, Isolate*);
 void V8_EXPORT _ZN2v88TryCatchC1Ev(void* This) {
   _ZN2v88TryCatchC1EPNS_7IsolateE(This, Isolate::GetCurrent());
 }
+
+MaybeLocal<Function> V8_EXPORT
+_ZN2v88Function3NewENS_5LocalINS_7ContextEEEPFvRKNS_20FunctionCallbackInfoINS_5ValueEEEENS1_IS5_EEiNS_19ConstructorBehaviorE(
+    Local<Context> context, FunctionCallback callback, Local<Value> data,
+    int length, ConstructorBehavior behavior) {
+  return Function::New(context, callback, data, length, behavior);
+}
+
+MaybeLocal<Array> V8_EXPORT
+_ZN2v86Object16GetPropertyNamesENS_5LocalINS_7ContextEEENS_17KeyCollectionModeENS_14PropertyFilterENS_11IndexFilterE(
+    v8::Object* This, Local<Context> context, KeyCollectionMode mode,
+    PropertyFilter property_filter, IndexFilter index_filter) {
+  return This->GetPropertyNames(context, mode, property_filter, index_filter);
+}
 }
 
 void* v8::ArrayBuffer::Allocator::Reserve(size_t length) { UNIMPLEMENTED(); }
diff --git a/src/api.cc b/src/api.cc
index 28b4012ba4..ad6e58450c 100644
--- a/src/api.cc
+++ b/src/api.cc
@@ -229,6 +229,11 @@ namespace v8 {
 
 namespace {
 
+#if defined(UC_BUILD_CRASH_CALLBACK)
+static const char* g_last_few_messages_storage = nullptr;
+static const char* g_stack_trace_storage = nullptr;
+#endif  // defined(UC_BUILD_CRASH_CALLBACK)
+
 Local<Context> ContextFromNeverReadOnlySpaceObject(
     i::Handle<i::NeverReadOnlySpaceObject> obj) {
   return reinterpret_cast<v8::Isolate*>(obj->GetIsolate())->GetCurrentContext();
@@ -388,6 +393,11 @@ void i::V8::FatalProcessOutOfMemory(i::Isolate* isolate, const char* location,
 
   memset(last_few_messages, 0, Heap::kTraceRingBufferSize + 1);
   memset(js_stacktrace, 0, Heap::kStacktraceBufferSize + 1);
+#if defined(UC_BUILD_CRASH_CALLBACK)
+  // prepare for signal function to read
+  g_last_few_messages_storage = last_few_messages;
+  g_stack_trace_storage = js_stacktrace;
+#endif  // defined(UC_BUILD_CRASH_CALLBACK)
 
   intptr_t start_marker;
   heap_stats.start_marker = &start_marker;
@@ -452,6 +462,11 @@ void i::V8::FatalProcessOutOfMemory(i::Isolate* isolate, const char* location,
     PrintF("\n<--- JS stacktrace --->\n%s\n", js_stacktrace);
   }
   Utils::ReportOOMFailure(isolate, location, is_heap_oom);
+#if defined(UC_BUILD_CRASH_CALLBACK)
+  // The data becomes unreachable so we clear it
+  g_last_few_messages_storage = nullptr;
+  g_stack_trace_storage = nullptr;
+#endif  // defined(UC_BUILD_CRASH_CALLBACK)
   // If the fatal error handler returns, we stop execution.
   FATAL("API fatal error handler returned after process out of memory");
 }
@@ -11050,4 +11065,31 @@ void InvokeFunctionCallback(const v8::FunctionCallbackInfo<v8::Value>& info,
 #undef RESET_DEPRECATED_WARNINGS
 
 }  // namespace internal
+
+#if defined(UC_BUILD_CRASH_CALLBACK)
+const char* GetLastFewMessagesOnOOM() { return g_last_few_messages_storage; }
+
+const char* GetStackTraceOnOOM() { return g_stack_trace_storage; }
+
+int GetLastFewMessages(Isolate* isolate, char* buff) {
+  if (!isolate || !buff) return i::Heap::kTraceRingBufferSize;
+  i::Heap* heap = reinterpret_cast<i::Isolate*>(isolate)->heap();
+  heap->GetFromRingBufferPublic(buff);
+  return i::Heap::kTraceRingBufferSize;
+}
+
+int GetStackTrace(Isolate* isolate, char* buff) {
+  if (!isolate || !buff) return i::Heap::kStacktraceBufferSize;
+  i::FixedStringAllocator fixed(buff, i::Heap::kStacktraceBufferSize - 1);
+  i::StringStream accumulator(&fixed, i::StringStream::kPrintObjectConcise);
+  i::Isolate* internal_isolate = reinterpret_cast<i::Isolate*>(isolate);
+  i::Heap* heap = internal_isolate->heap();
+  if (heap->gc_state() == i::Heap::NOT_IN_GC) {
+    internal_isolate->PrintStack(&accumulator, i::Isolate::kPrintStackConcise);
+  } else {
+    accumulator.Add("Cannot get stack trace in GC.");
+  }
+  return i::Heap::kStacktraceBufferSize;
+}
+#endif  // defined(UC_BUILD_CRASH_CALLBACK)
 }  // namespace v8
diff --git a/src/arm/assembler-arm.cc b/src/arm/assembler-arm.cc
index 576bcb30f6..ecdd1f8877 100644
--- a/src/arm/assembler-arm.cc
+++ b/src/arm/assembler-arm.cc
@@ -510,6 +510,10 @@ const Instr kBlxRegMask =
     15 * B24 | 15 * B20 | 15 * B16 | 15 * B12 | 15 * B8 | 15 * B4;
 const Instr kBlxRegPattern =
     B24 | B21 | 15 * B16 | 15 * B12 | 15 * B8 | BLX;
+#if defined(UC_BUILD_TF_LLVM_BACKEND)
+const Instr kBlOffsetMask = B27 | B26 | B25 | B24;
+const Instr kBlOffsetPattern = B27 | B25 | B24;
+#endif
 const Instr kBlxIp = al | kBlxRegPattern | ip.code();
 const Instr kMovMvnMask = 0x6D * B21 | 0xF * B16;
 const Instr kMovMvnPattern = 0xD * B21;
@@ -644,6 +648,9 @@ Instr Assembler::SetLdrRegisterImmediateOffset(Instr instr, int offset) {
   bool positive = offset >= 0;
   if (!positive) offset = -offset;
   DCHECK(is_uint12(offset));
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  CHECK(is_uint12(offset));
+#endif
   // Set bit indicating whether the offset should be added.
   instr = (instr & ~B23) | (positive ? B23 : 0);
   // Set the actual offset.
@@ -767,6 +774,11 @@ bool Assembler::IsBlxIp(Instr instr) {
   return instr == kBlxIp;
 }
 
+#if defined(UC_BUILD_TF_LLVM_BACKEND)
+bool Assembler::IsBlOffset(Instr instr) {
+  return (instr & kBlOffsetMask) == kBlOffsetPattern;
+}
+#endif
 
 bool Assembler::IsTstImmediate(Instr instr) {
   return (instr & (B27 | B26 | I | kOpCodeMask | S | kRdMask)) ==
diff --git a/src/arm/assembler-arm.h b/src/arm/assembler-arm.h
index 2e71ce59e6..361406c435 100644
--- a/src/arm/assembler-arm.h
+++ b/src/arm/assembler-arm.h
@@ -1494,6 +1494,9 @@ class Assembler : public AssemblerBase {
   static bool IsVldrDPcImmediateOffset(Instr instr);
   static bool IsBlxReg(Instr instr);
   static bool IsBlxIp(Instr instr);
+#if defined(UC_BUILD_TF_LLVM_BACKEND)
+  static bool IsBlOffset(Instr instr);
+#endif
   static bool IsTstImmediate(Instr instr);
   static bool IsCmpRegister(Instr instr);
   static bool IsCmpImmediate(Instr instr);
@@ -1701,8 +1704,18 @@ class Assembler : public AssemblerBase {
   void bind_to(Label* L, int pos);
   void next(Label* L);
 
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+ public:
+  void RecordRelocInfo(RelocInfo::Mode rmode, intptr_t data = 0);
+  void reset_pc(int pc_offset) { pc_ = buffer_ + pc_offset; }
+  void LLVMGrowBuffer() { GrowBuffer(); }
+  int LLVMAddCodeTarget(Handle<Code> target) { return AddCodeTarget(target); }
+
+ private:
+#else
   // Record reloc info for current pc_
   void RecordRelocInfo(RelocInfo::Mode rmode, intptr_t data = 0);
+#endif
   void ConstantPoolAddEntry(int position, RelocInfo::Mode rmode,
                             intptr_t value);
   void ConstantPoolAddEntry(int position, Double value);
diff --git a/src/arm/cpu-arm.cc b/src/arm/cpu-arm.cc
index d7110946c7..e00e8739a9 100644
--- a/src/arm/cpu-arm.cc
+++ b/src/arm/cpu-arm.cc
@@ -22,118 +22,10 @@
 
 namespace v8 {
 namespace internal {
-#if defined(UC_BUILD) && !USE_SIMULATOR
-namespace {
-#if !defined(CPU_SETSIZE)
-#define CPU_SETSIZE 32
-
-#define __CPU_BITTYPE unsigned long int /* mandated by the kernel  */
-#define __CPU_BITSHIFT 5                /* should be log2(BITTYPE) */
-#define __CPU_BITS (1 << __CPU_BITSHIFT)
-#define __CPU_ELT(x) ((x) >> __CPU_BITSHIFT)
-#define __CPU_MASK(x) ((__CPU_BITTYPE)1 << ((x) & (__CPU_BITS - 1)))
-
-typedef struct { __CPU_BITTYPE __bits[CPU_SETSIZE / __CPU_BITS]; } cpu_set_t;
-#define CPU_ZERO(set_)     \
-  do {                     \
-    (set_)->__bits[0] = 0; \
-  } while (0)
-
-#define CPU_SET(cpu_, set_)                                          \
-  do {                                                               \
-    size_t __cpu = (cpu_);                                           \
-    if (__cpu < CPU_SETSIZE) (set_)->__bits[0] |= __CPU_MASK(__cpu); \
-  } while (0)
-#endif
-class Flusher {
- public:
-  Flusher() = default;
-  ~Flusher() = default;
-
-  void Flush(void* start, size_t size);
-
- private:
-  class FlusherCpuScope {
-   public:
-    FlusherCpuScope();
-    ~FlusherCpuScope();
-
-   private:
-    void CallSetAffinity(const cpu_set_t& cpuset);
-  };
-  void DoFlush(void* start, size_t size);
-  void GenerateCode(Isolate*, int constant);
-};
-
-Flusher::FlusherCpuScope::FlusherCpuScope() {
-  cpu_set_t cpuset;
-  CPU_ZERO(&cpuset);
-  CPU_SET(0, &cpuset);
-  CallSetAffinity(cpuset);
-}
-
-Flusher::FlusherCpuScope::~FlusherCpuScope() {
-  cpu_set_t cpuset;
-  memset(&cpuset, 0xff, sizeof(cpu_set_t));
-  CallSetAffinity(cpuset);
-}
-
-void Flusher::FlusherCpuScope::CallSetAffinity(const cpu_set_t& cpuset) {
-  int ret = syscall(__NR_sched_setaffinity, 0, sizeof(cpu_set_t), &cpuset);
-  if (ret != 0) {
-    PrintF("CallSetAffinity failed: %s %d\n", strerror(errno), errno);
-  }
-}
-
-void Flusher::Flush(void* start, size_t size) {
-  FlusherCpuScope scope;
-  DoFlush(start, size);
-}
-
-void Flusher::DoFlush(void* start, size_t size) {
-  register uint32_t beg asm("r0") = reinterpret_cast<uint32_t>(start);
-  register uint32_t end asm("r1") = beg + size;
-  register uint32_t flg asm("r2") = 0;
-#ifdef __clang__
-  // This variant of the asm avoids a constant pool entry, which can be
-  // problematic when LTO'ing. It is also slightly shorter.
-  register uint32_t scno asm("r7") = __ARM_NR_cacheflush;
-
-  asm volatile("svc 0\n"
-               :
-               : "r"(beg), "r"(end), "r"(flg), "r"(scno)
-               : "memory");
-#else
-  // Use a different variant of the asm with GCC because some versions doesn't
-  // support r7 as an asm input.
-  asm volatile(
-      // This assembly works for both ARM and Thumb targets.
-
-      // Preserve r7; it is callee-saved, and GCC uses it as a frame pointer for
-      // Thumb targets.
-      "  push {r7}\n"
-      // r0 = beg
-      // r1 = end
-      // r2 = flags (0)
-      "  ldr r7, =%c[scno]\n"  // r7 = syscall number
-      "  svc 0\n"
-
-      "  pop {r7}\n"
-      :
-      : "r"(beg), "r"(end), "r"(flg), [scno] "i"(__ARM_NR_cacheflush)
-      : "memory");
-#endif
-}
-}
-#endif
-
 void CpuFeatures::FlushICache(void* start, size_t size) {
 #if !defined(USE_SIMULATOR)
 #if V8_OS_QNX
   msync(start, size, MS_SYNC | MS_INVALIDATE_ICACHE);
-#elif defined(UC_BUILD)
-  Flusher flusher;
-  flusher.Flush(start, size);
 #else
   register uint32_t beg asm("r0") = reinterpret_cast<uint32_t>(start);
   register uint32_t end asm("r1") = beg + size;
diff --git a/src/arm/disasm-arm.cc b/src/arm/disasm-arm.cc
index 5dab458889..bbf0f691dd 100644
--- a/src/arm/disasm-arm.cc
+++ b/src/arm/disasm-arm.cc
@@ -1343,7 +1343,11 @@ void Decoder::DecodeType3(Instruction* instr) {
             Format(instr, "sbfx'cond 'rd, 'rm, 'f");
           }
         } else {
+#if defined(UC_BUILD_TF_LLVM_BACKEND)
+          Unknown(instr);
+#else
           UNREACHABLE();
+#endif
         }
       } else if (!instr->HasW() && (instr->Bits(6, 4) == 0x1)) {
         uint32_t lsbit = static_cast<uint32_t>(instr->Bits(11, 7));
diff --git a/src/builtins/builtins-math-gen.cc b/src/builtins/builtins-math-gen.cc
index 952bdda5de..b18bb30909 100644
--- a/src/builtins/builtins-math-gen.cc
+++ b/src/builtins/builtins-math-gen.cc
@@ -172,6 +172,9 @@ void MathBuiltinsAssembler::MathMaxMin(
 
 // ES6 #sec-math.acos
 TF_BUILTIN(MathAcos, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Acos);
@@ -179,6 +182,9 @@ TF_BUILTIN(MathAcos, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.acosh
 TF_BUILTIN(MathAcosh, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Acosh);
@@ -186,6 +192,9 @@ TF_BUILTIN(MathAcosh, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.asin
 TF_BUILTIN(MathAsin, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Asin);
@@ -193,6 +202,9 @@ TF_BUILTIN(MathAsin, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.asinh
 TF_BUILTIN(MathAsinh, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Asinh);
@@ -200,6 +212,9 @@ TF_BUILTIN(MathAsinh, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.atan
 TF_BUILTIN(MathAtan, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Atan);
@@ -207,6 +222,9 @@ TF_BUILTIN(MathAtan, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.atanh
 TF_BUILTIN(MathAtanh, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Atanh);
@@ -214,6 +232,9 @@ TF_BUILTIN(MathAtanh, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.atan2
 TF_BUILTIN(MathAtan2, CodeStubAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* y = Parameter(Descriptor::kY);
   Node* x = Parameter(Descriptor::kX);
@@ -227,6 +248,9 @@ TF_BUILTIN(MathAtan2, CodeStubAssembler) {
 
 // ES6 #sec-math.ceil
 TF_BUILTIN(MathCeil, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathRoundingOperation(context, x, &CodeStubAssembler::Float64Ceil);
@@ -234,6 +258,9 @@ TF_BUILTIN(MathCeil, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.cbrt
 TF_BUILTIN(MathCbrt, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Cbrt);
@@ -299,6 +326,9 @@ TF_BUILTIN(MathClz32, CodeStubAssembler) {
 
 // ES6 #sec-math.cos
 TF_BUILTIN(MathCos, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Cos);
@@ -306,6 +336,9 @@ TF_BUILTIN(MathCos, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.cosh
 TF_BUILTIN(MathCosh, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Cosh);
@@ -313,6 +346,9 @@ TF_BUILTIN(MathCosh, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.exp
 TF_BUILTIN(MathExp, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Exp);
@@ -320,6 +356,9 @@ TF_BUILTIN(MathExp, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.expm1
 TF_BUILTIN(MathExpm1, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Expm1);
@@ -327,6 +366,9 @@ TF_BUILTIN(MathExpm1, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.floor
 TF_BUILTIN(MathFloor, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathRoundingOperation(context, x, &CodeStubAssembler::Float64Floor);
@@ -334,6 +376,9 @@ TF_BUILTIN(MathFloor, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.fround
 TF_BUILTIN(MathFround, CodeStubAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   Node* x_value = TruncateTaggedToFloat64(context, x);
@@ -345,6 +390,9 @@ TF_BUILTIN(MathFround, CodeStubAssembler) {
 
 // ES6 #sec-math.imul
 TF_BUILTIN(MathImul, CodeStubAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   Node* y = Parameter(Descriptor::kY);
@@ -357,6 +405,9 @@ TF_BUILTIN(MathImul, CodeStubAssembler) {
 
 // ES6 #sec-math.log
 TF_BUILTIN(MathLog, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Log);
@@ -364,6 +415,9 @@ TF_BUILTIN(MathLog, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.log1p
 TF_BUILTIN(MathLog1p, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Log1p);
@@ -371,6 +425,9 @@ TF_BUILTIN(MathLog1p, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.log10
 TF_BUILTIN(MathLog10, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Log10);
@@ -378,6 +435,9 @@ TF_BUILTIN(MathLog10, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.log2
 TF_BUILTIN(MathLog2, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Log2);
@@ -394,6 +454,9 @@ CodeStubAssembler::Node* MathBuiltinsAssembler::MathPow(Node* context,
 
 // ES6 #sec-math.pow
 TF_BUILTIN(MathPow, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Return(MathPow(Parameter(Descriptor::kContext), Parameter(Descriptor::kBase),
                  Parameter(Descriptor::kExponent)));
 }
@@ -459,6 +522,9 @@ TF_BUILTIN(MathSign, CodeStubAssembler) {
 
 // ES6 #sec-math.sin
 TF_BUILTIN(MathSin, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Sin);
@@ -466,6 +532,9 @@ TF_BUILTIN(MathSin, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.sinh
 TF_BUILTIN(MathSinh, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Sinh);
@@ -473,6 +542,9 @@ TF_BUILTIN(MathSinh, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.sqrt
 TF_BUILTIN(MathSqrt, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Sqrt);
@@ -480,6 +552,9 @@ TF_BUILTIN(MathSqrt, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.tan
 TF_BUILTIN(MathTan, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Tan);
@@ -487,6 +562,9 @@ TF_BUILTIN(MathTan, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.tanh
 TF_BUILTIN(MathTanh, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* context = Parameter(Descriptor::kContext);
   Node* x = Parameter(Descriptor::kX);
   MathUnaryOperation(context, x, &CodeStubAssembler::Float64Tanh);
@@ -501,6 +579,9 @@ TF_BUILTIN(MathTrunc, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.max
 TF_BUILTIN(MathMax, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   // TODO(ishell): use constants from Descriptor once the JSFunction linkage
   // arguments are reordered.
   Node* context = Parameter(Descriptor::kContext);
@@ -510,6 +591,9 @@ TF_BUILTIN(MathMax, MathBuiltinsAssembler) {
 
 // ES6 #sec-math.min
 TF_BUILTIN(MathMin, MathBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   // TODO(ishell): use constants from Descriptor once the JSFunction linkage
   // arguments are reordered.
   Node* context = Parameter(Descriptor::kContext);
diff --git a/src/builtins/builtins-number-gen.cc b/src/builtins/builtins-number-gen.cc
index cfc81612f2..7fea982548 100644
--- a/src/builtins/builtins-number-gen.cc
+++ b/src/builtins/builtins-number-gen.cc
@@ -930,6 +930,9 @@ TF_BUILTIN(Modulus, NumberBuiltinsAssembler) {
 }
 
 TF_BUILTIN(Exponentiate, NumberBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   VARIABLE(var_left, MachineRepresentation::kTagged);
   VARIABLE(var_right, MachineRepresentation::kTagged);
   Label do_number_exp(this), do_bigint_exp(this);
diff --git a/src/builtins/builtins-sharedarraybuffer-gen.cc b/src/builtins/builtins-sharedarraybuffer-gen.cc
index 52673bfd36..596b076722 100644
--- a/src/builtins/builtins-sharedarraybuffer-gen.cc
+++ b/src/builtins/builtins-sharedarraybuffer-gen.cc
@@ -135,6 +135,9 @@ void SharedArrayBufferBuiltinsAssembler::DebugSanityCheckAtomicIndex(
 #endif
 
 TF_BUILTIN(AtomicsLoad, SharedArrayBufferBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* array = Parameter(Descriptor::kArray);
   Node* index = Parameter(Descriptor::kIndex);
   Node* context = Parameter(Descriptor::kContext);
@@ -191,6 +194,9 @@ TF_BUILTIN(AtomicsLoad, SharedArrayBufferBuiltinsAssembler) {
 }
 
 TF_BUILTIN(AtomicsStore, SharedArrayBufferBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* array = Parameter(Descriptor::kArray);
   Node* index = Parameter(Descriptor::kIndex);
   Node* value = Parameter(Descriptor::kValue);
@@ -245,6 +251,9 @@ TF_BUILTIN(AtomicsStore, SharedArrayBufferBuiltinsAssembler) {
 }
 
 TF_BUILTIN(AtomicsExchange, SharedArrayBufferBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* array = Parameter(Descriptor::kArray);
   Node* index = Parameter(Descriptor::kIndex);
   Node* value = Parameter(Descriptor::kValue);
@@ -318,6 +327,9 @@ TF_BUILTIN(AtomicsExchange, SharedArrayBufferBuiltinsAssembler) {
 }
 
 TF_BUILTIN(AtomicsCompareExchange, SharedArrayBufferBuiltinsAssembler) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  state()->set_llvm_enabled(false);
+#endif
   Node* array = Parameter(Descriptor::kArray);
   Node* index = Parameter(Descriptor::kIndex);
   Node* old_value = Parameter(Descriptor::kOldValue);
@@ -400,6 +412,19 @@ TF_BUILTIN(AtomicsCompareExchange, SharedArrayBufferBuiltinsAssembler) {
         // || V8_TARGET_ARCH_PPC || V8_TARGET_ARCH_S390 || V8_TARGET_ARCH_S390X
 }
 
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+#define BINOP_BUILTIN(op)                                       \
+  TF_BUILTIN(Atomics##op, SharedArrayBufferBuiltinsAssembler) { \
+    state()->set_llvm_enabled(false);                           \
+    Node* array = Parameter(Descriptor::kArray);                \
+    Node* index = Parameter(Descriptor::kIndex);                \
+    Node* value = Parameter(Descriptor::kValue);                \
+    Node* context = Parameter(Descriptor::kContext);            \
+    AtomicBinopBuiltinCommon(array, index, value, context,      \
+                             &CodeAssembler::Atomic##op,        \
+                             Runtime::kAtomics##op);            \
+  }
+#else
 #define BINOP_BUILTIN(op)                                       \
   TF_BUILTIN(Atomics##op, SharedArrayBufferBuiltinsAssembler) { \
     Node* array = Parameter(Descriptor::kArray);                \
@@ -410,6 +435,7 @@ TF_BUILTIN(AtomicsCompareExchange, SharedArrayBufferBuiltinsAssembler) {
                              &CodeAssembler::Atomic##op,        \
                              Runtime::kAtomics##op);            \
   }
+#endif
 BINOP_BUILTIN(Add)
 BINOP_BUILTIN(Sub)
 BINOP_BUILTIN(And)
diff --git a/src/builtins/builtins-typed-array-gen.h b/src/builtins/builtins-typed-array-gen.h
index e74469187f..e559b95cd9 100644
--- a/src/builtins/builtins-typed-array-gen.h
+++ b/src/builtins/builtins-typed-array-gen.h
@@ -13,7 +13,11 @@ namespace internal {
 class TypedArrayBuiltinsAssembler : public BaseBuiltinsFromDSLAssembler {
  public:
   explicit TypedArrayBuiltinsAssembler(compiler::CodeAssemblerState* state)
-      : BaseBuiltinsFromDSLAssembler(state) {}
+      : BaseBuiltinsFromDSLAssembler(state) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+    state->set_llvm_enabled(false);
+#endif
+  }
 
   TNode<JSTypedArray> SpeciesCreateByLength(TNode<Context> context,
                                             TNode<JSTypedArray> exemplar,
diff --git a/src/builtins/builtins-utils-gen.h b/src/builtins/builtins-utils-gen.h
index 9984330980..e81b1515c1 100644
--- a/src/builtins/builtins-utils-gen.h
+++ b/src/builtins/builtins-utils-gen.h
@@ -48,6 +48,32 @@ class CodeAssemblerState;
     assembler.Generate##Name##Impl();                                    \
   }                                                                      \
   void Name##Assembler::Generate##Name##Impl()
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+
+#define TF_BUILTIN_LLVM(Name, AssemblerBase)                            \
+  class Name##Assembler : public AssemblerBase {                        \
+   public:                                                              \
+    typedef Builtin_##Name##_InterfaceDescriptor Descriptor;            \
+                                                                        \
+    explicit Name##Assembler(compiler::CodeAssemblerState* state)       \
+        : AssemblerBase(state) {}                                       \
+    void Generate##Name##Impl();                                        \
+                                                                        \
+    Node* Parameter(Descriptor::ParameterIndices index) {               \
+      return CodeAssembler::Parameter(static_cast<int>(index));         \
+    }                                                                   \
+  };                                                                    \
+  void Builtins::Generate_##Name(compiler::CodeAssemblerState* state) { \
+    Name##Assembler assembler(state);                                   \
+    state->set_llvm_enabled(true);                                      \
+    state->SetInitialDebugInformation(#Name, __FILE__, __LINE__);       \
+    if (Builtins::KindOf(Builtins::k##Name) == Builtins::TFJ) {         \
+      assembler.PerformStackCheck(assembler.GetJSContextParameter());   \
+    }                                                                   \
+    assembler.Generate##Name##Impl();                                   \
+  }                                                                     \
+  void Name##Assembler::Generate##Name##Impl()
+#endif
 
 }  // namespace internal
 }  // namespace v8
diff --git a/src/compiler/code-assembler.cc b/src/compiler/code-assembler.cc
index 0b77d10072..bf101d2706 100644
--- a/src/compiler/code-assembler.cc
+++ b/src/compiler/code-assembler.cc
@@ -23,6 +23,10 @@
 #include "src/objects-inl.h"
 #include "src/utils.h"
 #include "src/zone/zone.h"
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+#include "src/llvm/tf/v8-pass-manager.h"
+#endif
+
 
 namespace v8 {
 namespace internal {
@@ -82,7 +86,11 @@ CodeAssemblerState::CodeAssemblerState(Isolate* isolate, Zone* zone,
       stub_key_(stub_key),
       builtin_index_(builtin_index),
       code_generated_(false),
-      variables_(zone) {}
+      variables_(zone) {
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  set_llvm_enabled(true);
+#endif
+}
 
 CodeAssemblerState::~CodeAssemblerState() {}
 
@@ -156,6 +164,14 @@ void CodeAssembler::CallEpilogue() {
   if (state_->call_epilogue_) {
     state_->call_epilogue_();
   }
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  // Need to split the block, to make my liveness analysis pass able to work.
+  if (state_->is_llvm_enabled()) {
+    Label force_break(this);
+    Goto(&force_break);
+    Bind(&force_break);
+  }
+#endif
 }
 
 bool CodeAssembler::Word32ShiftIsSafe() const {
@@ -174,6 +190,45 @@ Handle<Code> CodeAssembler::GenerateCode(CodeAssemblerState* state,
   RawMachineAssembler* rasm = state->raw_assembler_.get();
   Schedule* schedule = rasm->Export();
 
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  if (state->is_llvm_enabled()) {
+    tf_llvm::V8PassManager pass_manager;
+    state->code_generated_ = true;
+    Handle<Code> code = pass_manager.Run(
+        rasm->isolate(), schedule, rasm->call_descriptor(), state->name(),
+        state->kind_, state->stub_key_, state->builtin_index_);
+#if 0
+    code->Print();
+    {
+      JumpOptimizationInfo jump_opt;
+      bool should_optimize_jumps =
+          rasm->isolate()->serializer_enabled() && FLAG_turbo_rewrite_far_jumps;
+
+      Handle<Code> code =
+          Pipeline::GenerateCodeForCodeStub(
+              rasm->isolate(), rasm->call_descriptor(), rasm->graph(), schedule,
+              state->kind_, state->name_, state->stub_key_, state->builtin_index_,
+              should_optimize_jumps ? &jump_opt : nullptr, rasm->poisoning_level(),
+              options)
+              .ToHandleChecked();
+
+      if (jump_opt.is_optimizable()) {
+        jump_opt.set_optimizing();
+
+        // Regenerate machine code
+        code =
+            Pipeline::GenerateCodeForCodeStub(
+                rasm->isolate(), rasm->call_descriptor(), rasm->graph(), schedule,
+                state->kind_, state->name_, state->stub_key_, state->builtin_index_,
+                &jump_opt, rasm->poisoning_level(), options)
+                .ToHandleChecked();
+      }
+      code->Print();
+    }
+#endif
+    return code;
+  }
+#endif
   JumpOptimizationInfo jump_opt;
   bool should_optimize_jumps =
       rasm->isolate()->serializer_enabled() && FLAG_turbo_rewrite_far_jumps;
diff --git a/src/compiler/code-assembler.h b/src/compiler/code-assembler.h
index 6419140a74..0b6da485a2 100644
--- a/src/compiler/code-assembler.h
+++ b/src/compiler/code-assembler.h
@@ -1393,6 +1393,10 @@ class V8_EXPORT_PRIVATE CodeAssemblerState {
 
   const char* name() const { return name_; }
   int parameter_count() const;
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  void set_llvm_enabled(bool enable) { llvm_enabled_ = enable; }
+  bool is_llvm_enabled() const { return llvm_enabled_; }
+#endif
 
 #if DEBUG
   void PrintCurrentBlock(std::ostream& os);
@@ -1420,6 +1424,9 @@ class V8_EXPORT_PRIVATE CodeAssemblerState {
   ZoneSet<CodeAssemblerVariable::Impl*> variables_;
   CodeAssemblerCallback call_prologue_;
   CodeAssemblerCallback call_epilogue_;
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+  bool llvm_enabled_ = false;
+#endif
 
   DISALLOW_COPY_AND_ASSIGN(CodeAssemblerState);
 };
diff --git a/src/globals.h b/src/globals.h
index ddb222438f..ec7b565734 100644
--- a/src/globals.h
+++ b/src/globals.h
@@ -1617,4 +1617,9 @@ namespace i = v8::internal;
 # define UC_BUILD_ENABLE_DISK_CACHE_PREDICATION 0
 #endif  // UC_BUILD_ENABLE_V8_CACHE
 
+// #if defined(UC_BUILD_TF_LLVM_BACKEND) && UC_BUILD_TF_LLVM_BACKEND
+// #define FEATURE_USE_SAMPLE_PGO
+// #define FEATURE_SAMPLE_PGO
+// #endif
+
 #endif  // V8_GLOBALS_H_
diff --git a/src/heap/heap.h b/src/heap/heap.h
index 0f3c9ea389..ade6d84337 100644
--- a/src/heap/heap.h
+++ b/src/heap/heap.h
@@ -403,7 +403,11 @@ class Heap {
       16 * kPointerMultiplier * ((1 << kPageSizeBits) / KB);
 
   static const int kTraceRingBufferSize = 512;
+#if defined(UC_BUILD_CRASH_CALLBACK)
+  static const int kStacktraceBufferSize = 32 * KB;
+#else
   static const int kStacktraceBufferSize = 512;
+#endif  // defined(UC_BUILD_CRASH_CALLBACK)
 
   static const int kNoGCFlags = 0;
   static const int kReduceMemoryFootprintMask = 1;
@@ -2282,6 +2286,11 @@ class Heap {
   FRIEND_TEST(HeapControllerTest, OldGenerationAllocationLimit);
 
   DISALLOW_COPY_AND_ASSIGN(Heap);
+
+#if defined(UC_BUILD_CRASH_CALLBACK)
+ public:
+  void GetFromRingBufferPublic(char* buffer) { GetFromRingBuffer(buffer); }
+#endif  // defined(UC_BUILD_CRASH_CALLBACK)
 };
 
 
diff --git a/src/inspector/BUILD.gn b/src/inspector/BUILD.gn
index 3951f7caad..e08b49942d 100644
--- a/src/inspector/BUILD.gn
+++ b/src/inspector/BUILD.gn
@@ -4,6 +4,11 @@
 
 import("../../gni/v8.gni")
 
+#if UC_BUILD_DISABLE_INSPECTOR_V8
+import("../../snapshot_toolchain.gni")
+
+#endif  // UC_BUILD_DISABLE_INSPECTOR_V8
+
 _inspector_protocol = v8_path_prefix + "/third_party/inspector_protocol"
 import("$_inspector_protocol/inspector_protocol.gni")
 
@@ -160,7 +165,7 @@ v8_source_set("inspector") {
   #if UC_BUILD_DISABLE_INSPECTOR_V8
   if (uc_build_disable_inspector_v8) {
     sources = []
-    sources = [
+    sources += [
       "inspected-context.cc",
       "inspected-context.h",
       "string-16.cc",
@@ -179,5 +184,6 @@ v8_source_set("inspector") {
       "v8-stack-trace-impl.h",
     ]
   }
+
   #endif  // UC_BUILD_DISABLE_INSPECTOR_V8
 }
diff --git a/src/interpreter/interpreter-generator.cc b/src/interpreter/interpreter-generator.cc
index ec728e4e4d..f7bafdbf3d 100644
--- a/src/interpreter/interpreter-generator.cc
+++ b/src/interpreter/interpreter-generator.cc
@@ -52,6 +52,27 @@ typedef CodeStubAssembler::Variable Variable;
   }                                                                   \
   void Name##Assembler::GenerateImpl()
 
+#define IGNITION_HANDLER_LLVM(Name, BaseAssembler)                    \
+  class Name##Assembler : public BaseAssembler {                      \
+   public:                                                            \
+    explicit Name##Assembler(compiler::CodeAssemblerState* state,     \
+                             Bytecode bytecode, OperandScale scale)   \
+        : BaseAssembler(state, bytecode, scale) {}                    \
+    static void Generate(compiler::CodeAssemblerState* state,         \
+                         OperandScale scale);                         \
+                                                                      \
+   private:                                                           \
+    void GenerateImpl();                                              \
+    DISALLOW_COPY_AND_ASSIGN(Name##Assembler);                        \
+  };                                                                  \
+  void Name##Assembler::Generate(compiler::CodeAssemblerState* state, \
+                                 OperandScale scale) {                \
+    Name##Assembler assembler(state, Bytecode::k##Name, scale);       \
+    state->SetInitialDebugInformation(#Name, __FILE__, __LINE__);     \
+    assembler.GenerateImpl();                                         \
+  }                                                                   \
+  void Name##Assembler::GenerateImpl()
+
 // LdaZero
 //
 // Load literal '0' into the accumulator.
diff --git a/src/interpreter/interpreter.cc b/src/interpreter/interpreter.cc
index 7efbfbc302..4570c624d7 100644
--- a/src/interpreter/interpreter.cc
+++ b/src/interpreter/interpreter.cc
@@ -293,7 +293,7 @@ bool Interpreter::IsDispatchTableInitialized() const {
 }
 
 const char* Interpreter::LookupNameOfBytecodeHandler(const Code* code) {
-#ifdef ENABLE_DISASSEMBLER
+#if defined(UC_BUILD_TF_LLVM_BACKEND)
 #define RETURN_NAME(Name, ...)                                 \
   if (dispatch_table_[Bytecodes::ToByte(Bytecode::k##Name)] == \
       code->entry()) {                                         \
@@ -301,7 +301,31 @@ const char* Interpreter::LookupNameOfBytecodeHandler(const Code* code) {
   }
   BYTECODE_LIST(RETURN_NAME)
 #undef RETURN_NAME
+#define RETURN_NAME(Name, ...)                                 \
+  if (dispatch_table_[Bytecodes::ToByte(Bytecode::k##Name) +   \
+                      (1 << kBitsPerByte)] == code->entry()) { \
+    return #Name;                                              \
+  }
+  BYTECODE_LIST(RETURN_NAME)
+#undef RETURN_NAME
+#define RETURN_NAME(Name, ...)                                 \
+  if (dispatch_table_[Bytecodes::ToByte(Bytecode::k##Name) +   \
+                      (2 << kBitsPerByte)] == code->entry()) { \
+    return #Name " (Double Scale)";                            \
+  }
+  BYTECODE_LIST(RETURN_NAME)
+#undef RETURN_NAME
+#else
+#ifdef ENABLE_DISASSEMBLER
+#define RETURN_NAME(Name, ...)                                 \
+  if (dispatch_table_[Bytecodes::ToByte(Bytecode::k##Name)] == \
+      code->entry()) {                                         \
+    return #Name " (Quadruple Scale)";                         \
+  }
+  BYTECODE_LIST(RETURN_NAME)
+#undef RETURN_NAME
 #endif  // ENABLE_DISASSEMBLER
+#endif
   return nullptr;
 }
 
diff --git a/src/objects.cc b/src/objects.cc
index bc786957f9..a534075168 100644
--- a/src/objects.cc
+++ b/src/objects.cc
@@ -15041,6 +15041,9 @@ void Code::Disassemble(const char* name, std::ostream& os, Address current_pc) {
     if (kind() == OPTIMIZED_FUNCTION) {
       table.HandlerTableReturnPrint(os);
     }
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && USE_SIMULATOR
+    table.HandlerTableReturnPrint(os);
+#endif
     os << "\n";
   }
 
diff --git a/src/profiler/cpu-profiler.cc b/src/profiler/cpu-profiler.cc
index 1c74dca124..155f6a65d9 100644
--- a/src/profiler/cpu-profiler.cc
+++ b/src/profiler/cpu-profiler.cc
@@ -17,6 +17,9 @@
 #include "src/log-inl.h"
 #include "src/profiler/cpu-profiler-inl.h"
 #include "src/vm-state-inl.h"
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && !defined(FEATURE_USE_SAMPLE_PGO)
+#include <fstream>
+#endif
 
 namespace v8 {
 namespace internal {
@@ -370,6 +373,13 @@ void CpuProfiler::StartProcessorIfNotStarted() {
   // Disable logging when using the new implementation.
   saved_is_logging_ = logger->is_logging_;
   logger->is_logging_ = false;
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && !defined(FEATURE_USE_SAMPLE_PGO)
+  char name[256];
+  snprintf(name, 256, "/sdcard/v8_profile_details_%08x.log",
+           static_cast<int>(time(nullptr)));
+  profile_detail_.reset(new std::ofstream(name));
+  if (profile_detail_->fail()) __builtin_trap();
+#endif
   if (!generator_) {
     generator_.reset(new ProfileGenerator(profiles_.get()));
     CreateEntriesForRuntimeCallStats();
diff --git a/src/profiler/cpu-profiler.h b/src/profiler/cpu-profiler.h
index febc154802..cd17b344b1 100644
--- a/src/profiler/cpu-profiler.h
+++ b/src/profiler/cpu-profiler.h
@@ -220,6 +220,9 @@ class CpuProfiler : public CodeEventObserver {
   ProfileGenerator* generator() const { return generator_.get(); }
   ProfilerEventsProcessor* processor() const { return processor_.get(); }
   Isolate* isolate() const { return isolate_; }
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && !defined(FEATURE_USE_SAMPLE_PGO)
+  std::ostream& os() { return *profile_detail_; }
+#endif
 
   ProfilerListener* profiler_listener_for_test() {
     return profiler_listener_.get();
@@ -239,6 +242,9 @@ class CpuProfiler : public CodeEventObserver {
   std::unique_ptr<ProfileGenerator> generator_;
   std::unique_ptr<ProfilerEventsProcessor> processor_;
   std::unique_ptr<ProfilerListener> profiler_listener_;
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && !defined(FEATURE_USE_SAMPLE_PGO)
+  std::unique_ptr<std::ostream> profile_detail_;
+#endif
   bool saved_is_logging_;
   bool is_profiling_;
 
diff --git a/src/profiler/profile-generator.cc b/src/profiler/profile-generator.cc
index 48f017bd3b..938c9ce223 100644
--- a/src/profiler/profile-generator.cc
+++ b/src/profiler/profile-generator.cc
@@ -16,6 +16,10 @@
 #include "src/tracing/traced-value.h"
 #endif
 #include "src/unicode.h"
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && !defined(FEATURE_USE_SAMPLE_PGO)
+#include "src/code-stubs.h"
+#include "src/interpreter/interpreter.h"
+#endif
 
 namespace v8 {
 namespace internal {
@@ -682,6 +686,20 @@ void CpuProfilesCollection::AddPathToCurrentProfiles(
   current_profiles_semaphore_.Signal();
 }
 
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && !defined(FEATURE_USE_SAMPLE_PGO)
+Isolate* CpuProfilesCollection::isolate() { return profiler_->isolate(); }
+
+std::ostream& CpuProfilesCollection::os() { return profiler_->os(); }
+
+ProfileGenerator::~ProfileGenerator() {
+  for (Code* code : code_set_) {
+    std::ostream& os = profiles_->os();
+    if (code->IsCode()) code->Print(os);
+  }
+  profiles_->os().flush();
+}
+#endif
+
 ProfileGenerator::ProfileGenerator(CpuProfilesCollection* profiles)
     : profiles_(profiles) {}
 
@@ -777,6 +795,71 @@ void ProfileGenerator::RecordTickSample(const TickSample& sample) {
       }
       stack_trace.push_back({entry, line_number});
     }
+#if 0 && defined(UC_BUILD_TF_LLVM_BACKEND) && !defined(FEATURE_USE_SAMPLE_PGO)
+    bool handled = false;
+    do {
+      const char* name = nullptr;
+      Isolate* isolate = profiles_->isolate();
+      if (!isolate->heap()->code_space()->ContainsSlow(
+              reinterpret_cast<i::Address>(sample.pc)))
+        break;
+      handled = true;
+      i::Code* code =
+          isolate->FindCodeObject(reinterpret_cast<i::Address>(sample.pc));
+      if (code) {
+        std::ostream& os = profiles_->os();
+        os << "kind = " << i::Code::Kind2String(code->kind()) << ";";
+        os << "offset = "
+           << static_cast<byte* const>(sample.pc) - code->raw_instruction_start()
+           << ";";
+
+        if (code->is_stub()) {
+          const char* n =
+              i::CodeStub::MajorName(i::CodeStub::GetMajorKey(code));
+          os << "major_key = " << (n == NULL ? "null" : n) << ";";
+        }
+        if (code->kind() == i::Code::BYTECODE_HANDLER) {
+          name = isolate->interpreter()->LookupNameOfBytecodeHandler(code);
+          if (name != nullptr) {
+            os << "name = " << name << ";";
+          }
+        } else {
+          // There are some handlers and ICs that we can also find names for
+          // with
+          // Builtins::Lookup.
+          name = isolate->builtins()->Lookup(code->raw_instruction_start());
+          if (name != nullptr) {
+            os << "name = " << name << ";";
+          }
+        }
+        os << "\n";
+      }
+    } while (false);
+#if 0
+    if (!handled) {
+      // Try native objects.
+      Dl_info info;
+      std::ostream& os = profiles_->os();
+      if (dladdr(sample.pc, &info)) {
+        os << "kind = native;offset = "
+           << reinterpret_cast<uintptr_t>(sample.pc) -
+                  reinterpret_cast<uintptr_t>(info.dli_fbase)
+           << ';' << "name = ";
+#if 0
+        if (info.dli_sname) {
+          os << info.dli_sname;
+        } else {
+          os << "unknown symbol";
+        }
+#endif
+        os << "unknown symbol";
+        os << " (of " << info.dli_fname << ");\n";
+      } else {
+        os << "kind = unknown native;offset = " << sample.pc << ";\n";
+      }
+    }
+#endif
+#endif
   }
 
   if (FLAG_prof_browser_mode) {
diff --git a/src/profiler/profile-generator.h b/src/profiler/profile-generator.h
index 3e301a4082..3cde437e46 100644
--- a/src/profiler/profile-generator.h
+++ b/src/profiler/profile-generator.h
@@ -413,6 +413,10 @@ class CpuProfilesCollection {
   const char* GetName(Name* name) { return resource_names_.GetName(name); }
   bool IsLastProfile(const char* title);
   void RemoveProfile(CpuProfile* profile);
+#if defined(UC_BUILD)
+  Isolate* isolate();
+  std::ostream& os();
+#endif
 
   // Called from profile generator thread.
   void AddPathToCurrentProfiles(base::TimeTicks timestamp,
@@ -437,6 +441,9 @@ class CpuProfilesCollection {
 class ProfileGenerator {
  public:
   explicit ProfileGenerator(CpuProfilesCollection* profiles);
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && !defined(FEATURE_USE_SAMPLE_PGO)
+  ~ProfileGenerator();
+#endif
 
   void RecordTickSample(const TickSample& sample);
 
@@ -448,6 +455,9 @@ class ProfileGenerator {
 
   CpuProfilesCollection* profiles_;
   CodeMap code_map_;
+#if defined(UC_BUILD_TF_LLVM_BACKEND) && !defined(FEATURE_USE_SAMPLE_PGO)
+  std::unordered_set<Code*> code_set_;
+#endif
 
   DISALLOW_COPY_AND_ASSIGN(ProfileGenerator);
 };
